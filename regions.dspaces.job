#!/bin/bash  
#SBATCH -J "regions_feng"  
#SBATCH -o "results/%j.out"  
#SBATCH -A prd157
#SBATCH -p compute
#SBATCH -n 52
#SBATCH -N 4
#SBATCH --export=ALL  
#SBATCH -t 00:20:00  

#print the configuration file 
echo "configurations:"
THISFILE=regions.dspaces.job
cat ${THISFILE}
echo "----------------"
echo "----------------"


#This job runs with 3 nodes  
#ibrun in verbose mode will give binding detail  
PBS_O_WORKDIR=/home/rlu/Workspaces/sequentialNpClustering
DS_SERVER=/home/rlu/Dataspacesroot/bin/dataspaces_server
PBS_RESULTDIR=${PBS_O_WORKDIR}/results/${SLURM_JOBID}

mkdir -pv ${PBS_RESULTDIR}
cd $PBS_O_WORKDIR

## Clean up
rm -f conf *.log srv.lck
rm -f dataspaces.conf

## Create dataspaces configuration file
# note that we now have 400 regions
echo "## Config file for DataSpaces
ndim = 3
dims = 500, 500, 500
max_versions = 1
max_readers = 51
lock_type = 2
" > dataspaces.conf

## Run DataSpaces servers
ibrun -n 1 ${DS_SERVER} -s 1 -c 51  >& ${PBS_RESULTDIR}/server.log &
## Give some time for the servers to load and startup
while [ ! -f conf ]; do
    sleep 1s
done
sleep 5s  # wait server to fill up the conf file

## Run writer application
ibrun -n 1 bin/put_regions >& ${PBS_RESULTDIR}/producer.log &

## Run reader application
ibrun -n 50 bin/get_regions >& ${PBS_RESULTDIR}/consumer.log &

## Wait for the entire workflow to finish
wait
